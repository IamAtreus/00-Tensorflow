{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxVC6YLNCzE+8t6QUwFRLz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamAtreus/00-Tensorflow/blob/main/Food_project_pure_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "nRAgosW55jzE",
        "outputId": "44d1b05a-5f1a-4cb5-8513-4a2f6cf58309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1zqeBlp0D9US7b0Jf6zyDzJMV6w73ThCv \n",
            "\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aNwdiGGNe2mNpzMZ2HP6InsZOg4Esy-9\n",
            "To: /content/466987.jpg\n",
            "100% 64.4k/64.4k [00:00<00:00, 66.4MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c8f856237446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Unzip the downloaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.zip'"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Download zip file https://drive.google.com/file/d/1zqeBlp0D9US7b0Jf6zyDzJMV6w73ThCv/view?usp=sharing\n",
        "! gdown 1zqeBlp0D9US7b0Jf6zyDzJMV6w73ThCv\n",
        "! gdown 1aNwdiGGNe2mNpzMZ2HP6InsZOg4Esy-9\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"data.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through pizza_steak directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "UzORTn8c97CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names (programmatically, this is much more helpful with a longer list of classes)\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(\"data/train/\") # turn our training path into a Python path\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "31cqFfcX-T0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View an image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  # Setup target directory (we'll view images from here)\n",
        "  target_folder = target_dir+target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "\n",
        "  # Read in the image and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\");\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "g2U7t0YA_itZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a random image from the training dataset\n",
        "img = view_random_image(target_dir=\"data/train/\",\n",
        "                        target_class=\"falafel\")"
      ],
      "metadata": {
        "id": "sarsTLaW_mhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the img (actually just a big array/tensor)\n",
        "img"
      ],
      "metadata": {
        "id": "iwED4fCP_ml3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the image shape\n",
        "img.shape # returns (width, height, colour channels)"
      ],
      "metadata": {
        "id": "PtM6hdKH_mps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup the train and test directories\n",
        "train_dir = \"data/train/\"\n",
        "test_dir = \"data/test/\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               batch_size=32, # number of images to process at a time \n",
        "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
        "                                               class_mode=\"binary\", # type of problem we're working on\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=10, \n",
        "                         kernel_size=3, # can also be (3, 3)\n",
        "                         activation=\"relu\", \n",
        "                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "                            padding=\"valid\"), # padding can also be 'same'\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\") # binary activation output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "9uSMBOO6_mtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the layers in our model\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "d7olBJig_mwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model to replicate the TensorFlow Playground model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(224, 224, 3)), # dense layers expect a 1-dimensional vector as input\n",
        "  tf.keras.layers.Dense(4, activation='relu'),\n",
        "  tf.keras.layers.Dense(4, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_2 = model_2.fit(train_data, # use same training data created above\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data, # use same validation data created above\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "ZJr9VXb9_m0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our second model's architecture\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "l06cJkwH_m3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model similar to model_1 but add an extra layer and increase the number of hidden units in each layer\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(224, 224, 3)), # dense layers expect a 1-dimensional vector as input\n",
        "  tf.keras.layers.Dense(100, activation='relu'), # increase number of neurons from 4 to 100 (for each layer)\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(100, activation='relu'), # add an extra layer\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_3 = model_3.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "U5g-Foa4_m7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out model_3 architecture\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "iS9C5Mxi_m-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data (requires function 'view_random_image' above)\n",
        "plt.figure()\n",
        "plt.subplot(1, 2, 1)\n",
        "steak_img = view_random_image(\"data/train/\", \"filet_mignon\")\n",
        "plt.subplot(1, 2, 2)\n",
        "pizza_img = view_random_image(\"data/train/\", \"fish_and_chips\")"
      ],
      "metadata": {
        "id": "lQKVxuc9_nCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and test directory paths\n",
        "train_dir = \"data/train/\"\n",
        "test_dir = \"data/test/\""
      ],
      "metadata": {
        "id": "Sp24VGHGGRGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test data generators and rescale the data \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)"
      ],
      "metadata": {
        "id": "MDdahcZXGRMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode='binary',\n",
        "                                               batch_size=32)\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(directory=test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             class_mode='binary',\n",
        "                                             batch_size=32)"
      ],
      "metadata": {
        "id": "5c2u-lq3GRRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample of a train data batch\n",
        "images, labels = train_data.next() # get the \"next\" batch of images/labels in train_data\n",
        "len(images), len(labels)"
      ],
      "metadata": {
        "id": "KRZLHj1mGRU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many batches are there?\n",
        "len(train_data)"
      ],
      "metadata": {
        "id": "k7MUYqibGRYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a CNN model (start with a baseline)"
      ],
      "metadata": {
        "id": "-Ca72ZKgGRcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the creating of our model a little easier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
        "from tensorflow.keras import Sequential"
      ],
      "metadata": {
        "id": "5jXZQRYUGRfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (this will be our baseline, a layer convolutional neural network)\n",
        "model_4 = Sequential([\n",
        "  Conv2D(filters=10, # filter is the number of sliding windows going across an input (higher = more complex model)\n",
        "         kernel_size=(3, 3), # the size of the sliding window going across an input\n",
        "         strides=(1, 1), # the size of the step the sliding window takes across an input \n",
        "         padding=\"valid\", # if \"same\", output shape is same as input shape, if \"valid\", output shape gets compressed\n",
        "         activation=\"relu\",\n",
        "         input_shape=(224, 224, 3)), # input layer (specify input shape)\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  Flatten(),\n",
        "  Dense(1, activation=\"sigmoid\") # output layer (working with binary classification so only 1 output neuron)                 \n",
        "])"
      ],
      "metadata": {
        "id": "pY6l45RaGRi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "7wCdDZTpGRmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our model\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "XOwk1qhVGRp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths of training and test data generators\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "9Vv-XbtyGRtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_4 = model_4.fit(train_data, # this is a combination of labels and sample data\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "DnnCPYdIGRwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the training curves\n",
        "import pandas as pd\n",
        "pd.DataFrame(history_4.history).plot(figsize=(10, 7));"
      ],
      "metadata": {
        "id": "rbOns1c5Kbma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training curves separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "  epochs = range(len(history.history[\"loss\"])) # how many epochs did we run for?\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label=\"training_loss\")\n",
        "  plt.plot(epochs, val_loss, label=\"val_loss\")\n",
        "  plt.title(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label=\"training_accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n",
        "  plt.title(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "eQjV5m5SKbpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BCBE0w6cKbtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (this is going to be our new baseline)\n",
        "model_5 = Sequential([\n",
        "  Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(pool_size=2),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "o-GsroAqKbwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ckZ9lIbpKbza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_5 = model_5.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "rhGy2AEMKb2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our model with max pooling\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "POfj4g28Kb5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_5)"
      ],
      "metadata": {
        "id": "0QWL1spNKb84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ImageDataGenerator training instance with data augmentation\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=0.2, # how much do you want to rotate an image?\n",
        "                                             shear_range=0.2, # how much do you want to shear an image?\n",
        "                                             zoom_range=0.2, # zoom in randomly on an image\n",
        "                                             width_shift_range=0.2, # move your iamge around on the x-axis\n",
        "                                             height_shift_range=0.2, # move your image around on the y-axis\n",
        "                                             horizontal_flip=True) # do you want to flip and image? \n",
        "\n",
        "# Create ImageDataGenerator without data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Create ImageDataGenerator without data augmentation for the test dataset\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)"
      ],
      "metadata": {
        "id": "mkhC3UWrKcAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and augment it from training directory\n",
        "print(\"Augmented training data:\")\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                   target_size=(224, 224),\n",
        "                                                                   batch_size=32,\n",
        "                                                                   class_mode=\"binary\",\n",
        "                                                                   shuffle=False) # for demonstration purposes only\n",
        "\n",
        "# Create non-augmented train data batches\n",
        "print(\"Non-augmented training data:\")\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"binary\",\n",
        "                                               shuffle=False)\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "# Create non-augmented test data batches\n",
        "print(\"Non-augmented test data:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMG_SIZE,\n",
        "                                             batch_size=32,\n",
        "                                             class_mode=\"binary\")"
      ],
      "metadata": {
        "id": "s3JRSDqKKcDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample data batches\n",
        "images, labels = train_data.next()\n",
        "augmented_images, augmented_labels = train_data_augmented.next() # note: labels aren't augmented... only data (images)"
      ],
      "metadata": {
        "id": "WjUvqormKcGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show original image and augmented image\n",
        "import random\n",
        "random_number = random.randint(0, 32) # our batch sizes are 32...\n",
        "print(f\"showing image number: {random_number}\")\n",
        "plt.imshow(images[random_number])\n",
        "plt.title(f\"Original image\")\n",
        "plt.axis(False)\n",
        "plt.figure()\n",
        "plt.imshow(augmented_images[random_number])\n",
        "plt.title(f\"Augmented image\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "T-eyzO5JKcJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model (same as model_5)\n",
        "model_6 = Sequential([\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(pool_size=2),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(1, activation=\"sigmoid\")                      \n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_6 = model_6.fit(train_data_augmented, # fitting model_6 on augmented training data\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_augmented),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "GvpPk3FYKcM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check our models training curves\n",
        "plot_loss_curves(history_6)"
      ],
      "metadata": {
        "id": "zXg8Wv6hKcP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and augment it and shuffle from training directory\n",
        "train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                            target_size=(224, 224),\n",
        "                                                                            class_mode=\"binary\",\n",
        "                                                                            batch_size=32,\n",
        "                                                                            shuffle=True) # shuffle data this time"
      ],
      "metadata": {
        "id": "6dR6ofYHK9PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (same as model_5 and model_6)\n",
        "model_7 = Sequential([\n",
        "  Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(1, activation=\"sigmoid\")                     \n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(), \n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_7 = model_7.fit(train_data_augmented_shuffled, # we're fitting on augmented and shuffled data now\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_augmented_shuffled),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "a9f0nHt-K9Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_7)"
      ],
      "metadata": {
        "id": "fu-tvEDbK9XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes we're working with\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "k4Hj2ZVEK9aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View our example image\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "\n",
        "! gdown 1aNwdiGGNe2mNpzMZ2HP6InsZOg4Esy-9\n",
        "\n",
        "testpic = mpimg.imread(\"466987.jpg\")\n",
        "plt.imshow(testpic)\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "2BIhDk9rK9dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import and image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turns it into a tensor and reshapes it \n",
        "  to (img_shape, img_shape, colour_channels).\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode the read file into a tensor\n",
        "  img = tf.image.decode_image(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, size=[img_shape, img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img"
      ],
      "metadata": {
        "id": "tTVyxpuCK9gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in and preprocess our custom image\n",
        "testpic = load_and_prep_image(\"466987.jpg\")\n",
        "testpic"
      ],
      "metadata": {
        "id": "PKF-3IilK9jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_7.predict(tf.expand_dims(testpic, axis=0))\n",
        "pred"
      ],
      "metadata": {
        "id": "4khGLVZ8K9mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can index the predicted class by rounding the prediction probability and indexing it on the class names\n",
        "pred_class = class_names[int(tf.round(pred))]\n",
        "pred_class"
      ],
      "metadata": {
        "id": "AbzZzMY7K9px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(model, filename, class_names=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction with model\n",
        "  and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class = class_names[int(tf.round(pred))]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "ZHwJ_IpwK9s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our model on a custom image\n",
        "pred_and_plot(model_7, \"466987.jpg\")"
      ],
      "metadata": {
        "id": "zv8cuWhTK9wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://drive.google.com/file/d/1zCkPV-pwwJaYFy34bbI55xNHo4O4HdFk/view?usp=sharing\n",
        "! gdown 1zCkPV-pwwJaYFy34bbI55xNHo4O4HdFk\n",
        "\n"
      ],
      "metadata": {
        "id": "BhULi8y6K9zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"data_66.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "id": "ZLn1cifGK92S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through 66 classes of food image data\n",
        "for dirpath, dirnames, filenames in os.walk(\"data/66/\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "ZJSeEiGKK95s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the train and test directories\n",
        "train_dir = \"data/66/train/\"\n",
        "test_dir = \"data/66/test/\""
      ],
      "metadata": {
        "id": "cbje3y1FK98z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "bTn1e6E1K9_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "import random\n",
        "img = view_random_image(target_dir=train_dir,\n",
        "                        target_class=random.choice(class_names))"
      ],
      "metadata": {
        "id": "bQpBpJ58K-DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rescale\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Load data in from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "h9JbETyPK-Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation\n",
        "\n",
        "# Create our model (very similar to previous models but actually the same as CNN explainer website)\n",
        "# How about we try and simplify the model first?\n",
        "# Let's try to remove 2 convolutional layers...\n",
        "model_9 = Sequential([\n",
        "  Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "m7hBv4nfK-Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with 2x conv layers removed\n",
        "history_9 = model_9.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "4MO-ttXT-iB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_8 = model_8.fit(train_data, # Different classes\n",
        "                        epochs=150,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "HvV7WJxiK-M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalaute on the test data\n",
        "model_8.evaluate(test_data)"
      ],
      "metadata": {
        "id": "FWgnuvRyi7EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the model's loss curves on the 10 classes\n",
        "plot_loss_curves(history_8)"
      ],
      "metadata": {
        "id": "sa6aFTkNi7Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How about we try and simplify the model first?\n",
        "# Let's try to remove 2 convolutional layers...\n",
        "model_9 = Sequential([\n",
        "  Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "UdiKrXVpi7Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with 2x conv layers removed\n",
        "history_9 = model_9.fit(train_data,\n",
        "                        epochs=150,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "61JblE0Mi7OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_9.summary()"
      ],
      "metadata": {
        "id": "iwmTB3eYi7RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.summary()"
      ],
      "metadata": {
        "id": "qBStaRH9i7Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlbXbPvpi7Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tsH8N0Li7bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-14L1fIi7eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iGANl3vIi7hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IfVMz8Ci7kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pB9uQ_vNi7oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHH3sN70i7rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XA0VLRJli7uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kS63sDARK-QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iExmgmlyK-TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q36gwpSmK-W2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}